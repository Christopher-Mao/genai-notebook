{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "673268f4-b1c1-4757-bc82-15f392a5fc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# comment the previous line if experiencing package issues and want to debug\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b71b70a-6489-45e0-8863-1d5a49dd3ec7",
   "metadata": {},
   "source": [
    "# Generative AI for Biomedical Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7af4d07c-e4d9-4b8d-a35e-31886b5180d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot find .env file\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea1c23c-6086-4300-90e5-ba6ac49337f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just makes outputs formatted a little better\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string: str):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafa2ee4-85fa-4b05-bf01-ccd1e703bdce",
   "metadata": {},
   "source": [
    "## Getting Started: Generate Responses with Open AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfb0a47-59aa-4871-aaa8-9d9c808cea86",
   "metadata": {},
   "source": [
    "The `OpenAI` class creates a Python object that you can then use to generate responses from any of their models. For the most part, other models use a similar API where you call class methods when generating outputs. Prior to running this cell, make sure that you have created a `.env` file containing your `OPENAI_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf51117d-a961-455b-9c33-ba63ef3d8afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # this loads .env into os.environ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "229e36ea-3321-4b69-a446-8cb46584d2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv(\"OPENAI_API_KEY\"))  # should not be None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc1af38c-38c2-44a5-917d-678ab9c601d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0634ff4-c85b-4acd-8122-4273da646b96",
   "metadata": {},
   "source": [
    "Responses are generated using the `create()` method. A [full list of parameters can be found here](https://github.com/openai/openai-python/blob/main/api.md#responses). If you are creating an application, look [using streaming respones](https://platform.openai.com/docs/guides/streaming-responses?api-mode=chat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51ea467b-c7b2-4f39-b64a-336d626231ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Performing CPR (Cardiopulmonary Resuscitation) can help save a person's life if their heart has stopped or they are not breathing. Here's a general guide on how to administer CPR to an adult:\n",
       "\n",
       "### Before Starting CPR:\n",
       "- **Check the scene:** Ensure the environment is safe.\n",
       "- **Check for responsiveness:** Shake the person gently and ask loudly, \"Are you okay?\"\n",
       "- **Call for help:** If unresponsive, call emergency services immediately (e.g., 911), or have someone else do it.\n",
       "- **Check for breathing:** Look, listen, and feel for normal breathing for about 10 seconds. If not breathing or only gasping, start CPR.\n",
       "\n",
       "### Performing CPR:\n",
       "1. **Position the person:**\n",
       "   - Lay the person flat on their back on a firm surface.\n",
       "   - Kneel beside their chest.\n",
       "\n",
       "2. **Chest compressions:**\n",
       "   - Place the heel of one hand on the center of the chest (sternum).\n",
       "   - Place your other hand on top, interlocking your fingers.\n",
       "   - Keep your arms straight and shoulders directly above your hands.\n",
       "   - Compress the chest at least 2 inches (5 cm) deep.\n",
       "   - Allow the chest to fully recoil between compressions.\n",
       "   - Perform compressions at a rate of about 100-120 per minute (think of the beat of the song \"Stayin’ Alive\" by Bee Gees).\n",
       "\n",
       "3. **Rescue breaths (if trained and comfortable):**\n",
       "   - After 30 compressions, give 2 rescue breaths:\n",
       "     - Open the airway by tilting the head back slightly and lifting the chin.\n",
       "     - Pinch the nose shut.\n",
       "     - Cover the person's mouth with yours to create an airtight seal.\n",
       "     - Blow into their mouth for about 1 second, watching for chest rise.\n",
       "     - Continue with cycles of 30 compressions and 2 breaths.\n",
       "\n",
       "*Note:* If you're untrained or uncomfortable giving rescue breaths, perform **Hands-Only CPR**:\n",
       "- Just give continuous chest compressions at the recommended rate until emergency help arrives or the person shows signs of life.\n",
       "\n",
       "### Important:\n",
       "- Continue CPR until professional help takes over, the person starts to breathe normally, or you are physically unable to continue.\n",
       "\n",
       "---\n",
       "\n",
       "**Remember:** Proper training and certification are recommended for performing CPR effectively. Consider taking a certified CPR course through organizations such as the Red Cross or American Heart Association.\n",
       "\n",
       "Would you like information about CPR for children or infants?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_prompt = \"How do I administer CPR?\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    input=user_prompt,\n",
    ")\n",
    "\n",
    "printmd(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da47f1de-64a7-4cc4-b2e1-c8faa86dfb9d",
   "metadata": {},
   "source": [
    "You can also get responeses if wish to input an image instead. Take a look at [the OpenAI documentation](https://platform.openai.com/docs/overview) for a full list of all possible use-cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "573a9147-8c0f-4d7d-b290-defb143ce897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This image is an anatomical illustration of the human heart, lungs, and surrounding structures. It appears to be a detailed, schematic drawing likely from an old medical or anatomical textbook, showing different parts and regions involved in the cardiovascular and respiratory systems."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_prompt = \"What is this image\"\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/9/92/EB1911_Heart_-_Thoracic_Viscera.png\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": user_prompt},\n",
    "                {\"type\": \"input_image\", \"image_url\": f\"{image_url}\"},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "printmd(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4441e9-9f53-4597-9165-29a04e033d5a",
   "metadata": {},
   "source": [
    "## Customizing Model Responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47757fe-1407-41d2-8149-24ee0457a1be",
   "metadata": {},
   "source": [
    "### System Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009736f2-b5b1-447d-814a-8afe7b9424b4",
   "metadata": {},
   "source": [
    "If you take a look at the response from our prompt `How do I administer CPR?`, it seems quite wordy. Also, if I were a professional in the field, I already know a number of these things.  We can simply create a set of system instructions to make the model respond more like we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c897bace-ab17-4cb0-b6f5-c037f4676fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Ensure scene safety, then check for responsiveness and normal breathing. Call for help and activate emergency services. If unresponsive and not breathing normally, start CPR: \n",
       "1. **Chest compressions:** Place hands on the center of the chest, compress at 2 inches deep at 100-120/min. \n",
       "2. **Rescue breaths:** After 30 compressions, open the airway, pinch the nose, and give 2 breaths if trained and comfortable. Repeat cycles. Use an AED asap."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_instructions = \"\"\"\n",
    "You are an expert emergency physician with decades of experience in CPR. The user is also a clinician.\n",
    "Keep responses under 100 words.\n",
    "\"\"\"\n",
    "user_prompt = \"How do I administer CPR?\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    instructions=system_instructions,\n",
    "    input=user_prompt,\n",
    ")\n",
    "\n",
    "printmd(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c29d6d1-be93-4d3b-bcc3-f1c85df82fc3",
   "metadata": {},
   "source": [
    "With just a few system instructions, I was able to completely change the model to perform in a much more precise, direct, and concise manner. This is known as **prompt engineering** and can be a very powerful tool for changing model performance. [This guide](https://www.promptingguide.ai/) is a fantastic resource to get started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ed9b5e-2e86-4c31-99f3-5f0960c3b0e4",
   "metadata": {},
   "source": [
    "### Temperature, Top P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d6bebd-6c30-4733-b1c8-a6eb86b17e72",
   "metadata": {},
   "source": [
    "Let's take a look at repeated responses from our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b64b926-2998-4290-a7f0-1b6e61e49a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Response 1 Output:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Ensure scene safety, check responsiveness, and call for help. If unresponsive and no breathing, start CPR: \n",
       "1. Place hands on the center of the chest.\n",
       "2. Compress at least 2 inches deep at a rate of 100-120 per minute.\n",
       "3. Allow full chest recoil.\n",
       "4. For adults, give 30 compressions, then 2 rescue breaths if trained and comfortable.\n",
       "5. Continue until EMS arrives, the victim recovers, or you are unable to continue. Use an AED as soon as available."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Response 2 Output:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Ensure scene safety. Check responsiveness—shake and shout. Call for help and activate emergency services. Open the airway, check for breathing and pulse (10 seconds). If no pulse and not breathing normally, start CPR:  \n",
       "1. Compressions: 30 chest compressions at 2 inches deep, rate 100-120/min.  \n",
       "2. Airway: Tilt head, lift chin.  \n",
       "3. Breaths: 2 rescue breaths if trained and comfortable, each lasting 1 second, watching for chest rise.  \n",
       "Repeat cycles. Use AED as soon as available."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Response 3 Output:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Check responsiveness, shout for help, and call 911. If unresponsive and no breathing or abnormal breathing, start CPR. Place hands on the center of the chest, push hard and fast at 2 inches depth and 100-120 compressions per minute (like the beat of \"Stayin’ Alive\"). After 30 compressions, deliver 2 rescue breaths if trained and comfortable. Continue CPR until help arrives, the person shows signs of life, or you're unable to continue."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "system_instructions = \"\"\"\n",
    "You are an expert emergency physician with decades of experience in CPR. The user is also a clinician.\n",
    "Keep responses under 100 words.\n",
    "\"\"\"\n",
    "user_prompt = \"How do I administer CPR?\"\n",
    "\n",
    "for i in range(3):\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        instructions=system_instructions,\n",
    "        input=user_prompt,\n",
    "    )\n",
    "\n",
    "    printmd(f\"#### Response {i+1} Output:\")\n",
    "    printmd(response.output_text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b4b6a2-b9b8-4e29-b486-5702e978e942",
   "metadata": {},
   "source": [
    "Notice that responses are a little bit different each time. That is because when the model chooses which token to use next, there is a degree of randomness involved. This can be modified by two parameters:\n",
    "\n",
    "* **Temperature**: This skews the next token distribution towards the most likely token (low) or flattens the distribution (high). The values range from 0 to 2. Low temperatures makes responses more deterministic and high makes responses more creative.\n",
    "* **Top P**: Only considers top tokens summing to cumulative probability $p$. Values range from 0 to 1. Low top P values focus only on most probable tokens while high focusses on all possible tokens.\n",
    "\n",
    "It is generally recommended to choose either temperature or top P when controlling randomness. For medical purposes, it's recommended to keep these values low. Let's see what happens when we do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28c2390a-7d62-40c8-8056-e472e95a99d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Response 1 Output:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Ensure scene safety, then check responsiveness and breathing. Call for emergency help. If unresponsive and not breathing or only gasping, start CPR: \n",
       "\n",
       "1. **Chest Compressions:** Place hands on the center of the chest, compress at least 2 inches deep at 100-120/min.\n",
       "2. **Rescue Breaths:** After 30 compressions, give 2 breaths if trained and comfortable, each over 1 second, watching for chest rise.\n",
       "3. **Continue:** Repeat cycles until help arrives, the patient recovers, or you are unable to continue. Use an AED as soon as available."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Response 2 Output:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Ensure scene safety, check responsiveness, and call for help. If unresponsive and no breathing or abnormal breathing, start CPR: \n",
       "\n",
       "1. **Chest Compressions:** Place hands on the center of the chest, compress at least 2 inches deep at a rate of 100-120/min.\n",
       "2. **Rescue Breaths:** After 30 compressions, give 2 breaths if trained and comfortable, each lasting 1 second, watching for chest rise.\n",
       "3. **Continue:** Repeat cycles until help arrives, the patient recovers, or you're unable to continue. Use an AED as soon as available."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Response 3 Output:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Ensure scene safety, check responsiveness, and call for help. If unresponsive and no breathing or abnormal breathing, start CPR: \n",
       "\n",
       "1. **Chest Compressions:** Place hands on the center of the chest, compress at least 2 inches deep at a rate of 100-120 per minute.\n",
       "2. **Rescue Breaths:** After 30 compressions, give 2 breaths if trained and comfortable, each lasting about 1 second, watching for chest rise.\n",
       "3. **Continue:** Repeat cycles until help arrives, the person recovers, or you are unable to continue. Use an AED as soon as available."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "system_instructions = \"\"\"\n",
    "You are an expert emergency physician with decades of experience in CPR. The user is also a clinician.\n",
    "Keep responses under 100 words.\n",
    "\"\"\"\n",
    "user_prompt = \"How do I administer CPR?\"\n",
    "\n",
    "for i in range(3):\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        instructions=system_instructions,\n",
    "        input=user_prompt,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    printmd(f\"#### Response {i+1} Output:\")\n",
    "    printmd(response.output_text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76706b77-d7e2-4f39-8f2b-379f000a2d21",
   "metadata": {},
   "source": [
    "While not exactly the same (there is still some degree of randomness inherently within the model), for the most part responses are much more similar than they were before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfb8090-9286-4007-8b75-1ac9e931e824",
   "metadata": {},
   "source": [
    "### Tool Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee7ae9f-fe49-4ab6-9053-ed4308554f96",
   "metadata": {},
   "source": [
    "Sometimes, you may have a specific function that you would like to call that performs a specific task that supplments the LLM's performance. This may involve querying an API and getting a reponse or running a deterministic model on data you recieve from the LLM. In these cases, you will want to use a tool call. Consider an example where you want to know the weather in San Antonio, TX. You would do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb8ae2b3-dbfe-4ac0-890b-5949f3e2bec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current temperature in San Antonio, TX is approximately 89.3°F.\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Create tool call function\n",
    "def get_weather(latitude, longitude):\n",
    "    \"\"\"This function get's the weather from the lattitude and longititude of the provided location\"\"\"\n",
    "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m&temperature_unit=fahrenheit\")\n",
    "    data = response.json()\n",
    "    return data['current']['temperature_2m']\n",
    "\n",
    "# Step 1: Call model with get_weather tool defined\n",
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get current temperature for provided coordinates in Fahrenheit.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"latitude\": {\"type\": \"number\"},\n",
    "            \"longitude\": {\"type\": \"number\"}\n",
    "        },\n",
    "        \"required\": [\"latitude\", \"longitude\"],\n",
    "        \"additionalProperties\": False\n",
    "    },\n",
    "    \"strict\": True\n",
    "}]\n",
    "input_messages = [{\"role\": \"user\", \"content\": \"What is the weather like in San Antonio, TX today?\"}]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    input=input_messages,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "# Step 2: Execute get_weather function\n",
    "tool_call = response.output[0]\n",
    "args = json.loads(tool_call.arguments)\n",
    "\n",
    "result = get_weather(args[\"latitude\"], args[\"longitude\"])\n",
    "\n",
    "# Step 3: Supply result and call model again\n",
    "input_messages.append(tool_call)                 # append model's function call message\n",
    "input_messages.append({                          # append result message\n",
    "    \"type\": \"function_call_output\",\n",
    "    \"call_id\": tool_call.call_id,\n",
    "    \"output\": str(result)\n",
    "})\n",
    "\n",
    "response_2 = client.responses.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    input=input_messages,\n",
    "    tools=tools,\n",
    ")\n",
    "print(response_2.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a53b01e-9971-430a-a40e-8cf919766eac",
   "metadata": {},
   "source": [
    "## Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba75cc80-1386-412d-98ec-cef4c2352a9c",
   "metadata": {},
   "source": [
    "Reasoning models have been built that are trained with reinforcment learning. These models have been shown to excel in harder problems such as STEM related fields. OpenAI has built the o-series of models for this task. Consider this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fec4fb11-82a2-4744-b9a3-deebadcc3372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here are three especially promising antibiotic leads—each comes from an untapped microbial source, works by a new mechanism, and shows activity against high-priority pathogens with little or no cross-resistance:\n",
       "\n",
       "1. Teixobactin  \n",
       "   • Source & discovery: Cultured from previously “uncultivable” soil bacteria using the iChip method.  \n",
       "   • Mechanism: Binds lipid II and lipid III precursors of peptidoglycan and teichoic acids, blocking cell‐wall assembly in Gram-positives.  \n",
       "   • Why investigate it?  \n",
       "     – Potent in vitro and in vivo against MRSA, VRE, Mycobacterium tuberculosis, C. difficile, etc.  \n",
       "     – No resistant mutants have emerged in the lab after repeated exposure.  \n",
       "     – A rich scaffold for medicinal chemistry (modifying the depsipeptide macrocycle to improve PK/solubility).\n",
       "\n",
       "2. Darobactin  \n",
       "   • Source & discovery: A ribosomally synthesized peptide from Photorhabdus symbionts of nematodes.  \n",
       "   • Mechanism: Specifically binds BamA, the essential β-barrel assembly machine in Gram-negative outer membranes, crippling membrane biogenesis.  \n",
       "   • Why investigate it?  \n",
       "     – Potent against ESKAPE Gram-negatives (E. coli, K. pneumoniae, A. baumannii, P. aeruginosa) in animal models.  \n",
       "     – Novel target (no existing clinical drug hits BamA), so no cross-resistance with β-lactams, polymyxins, etc.  \n",
       "     – Peptidic scaffold amenable to optimization for stability and spectrum.\n",
       "\n",
       "3. Odilorhabdins  \n",
       "   • Source & discovery: Nonribosomal peptides from Xenorhabdus and Photorhabdus insect pathogens.  \n",
       "   • Mechanism: Bind a new site on the 30S ribosomal subunit, inducing miscoding and premature termination—distinct from aminoglycosides, tetracyclines or macrolides.  \n",
       "   • Why investigate them?  \n",
       "     – Broad-spectrum activity against Gram-positive and Gram-negative MDR strains, including carbapenem-resistant Enterobacterales.  \n",
       "     – No cross-resistance with current ribosomal antibiotics.  \n",
       "     – Amenable to SAR optimization: early analogs show improved metabolic stability and reduced mammalian toxicity.\n",
       "\n",
       "Collectively, these three scaffolds:  \n",
       "• Exploit wholly new bacterial targets or binding sites.  \n",
       "• Show potent in vivo efficacy against WHO high-priority pathogens.  \n",
       "• Have so far evaded common resistance mechanisms.  \n",
       "• Provide chemically tractable starting points for lead optimization (improving pharmacokinetics, spectrum, safety).  \n",
       "Exploring them further—through scale-up, analog synthesis, mechanism-of-resistance studies and preclinical evaluation—could yield the next generation of urgently needed antibiotics."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "What are three compounds we should consider investigating to \n",
    "advance research into new antibiotics? Why should we consider \n",
    "them?\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"o4-mini\",\n",
    "    reasoning={\"effort\": \"high\"},\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": prompt\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "printmd(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fb49445-9434-4b72-ba8d-42da4799c854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4-1106-preview\n",
      "dall-e-3\n",
      "dall-e-2\n",
      "gpt-4o-audio-preview-2024-10-01\n",
      "gpt-4-turbo-preview\n",
      "text-embedding-3-small\n",
      "babbage-002\n",
      "gpt-4\n",
      "text-embedding-ada-002\n",
      "chatgpt-4o-latest\n",
      "gpt-4o-mini-audio-preview\n",
      "gpt-4o-audio-preview\n",
      "gpt-4o-mini-realtime-preview\n",
      "gpt-4o-mini-realtime-preview-2024-12-17\n",
      "gpt-4.1-nano\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "gpt-4o-mini-search-preview\n",
      "gpt-4.1-nano-2025-04-14\n",
      "gpt-3.5-turbo-16k\n",
      "gpt-4o-realtime-preview\n",
      "davinci-002\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-4o-search-preview\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-3.5-turbo\n",
      "o3-mini-2025-01-31\n",
      "gpt-4o-mini-search-preview-2025-03-11\n",
      "gpt-4-0125-preview\n",
      "gpt-4o-2024-11-20\n",
      "gpt-4o-2024-05-13\n",
      "text-embedding-3-large\n",
      "o1-2024-12-17\n",
      "o1\n",
      "gpt-4-0613\n",
      "o1-mini\n",
      "gpt-4o-mini-tts\n",
      "o1-pro\n",
      "gpt-4o-transcribe\n",
      "gpt-4.5-preview\n",
      "o1-pro-2025-03-19\n",
      "gpt-4.5-preview-2025-02-27\n",
      "gpt-4o-search-preview-2025-03-11\n",
      "gpt-image-1\n",
      "o1-mini-2024-09-12\n",
      "tts-1-hd\n",
      "gpt-4o\n",
      "tts-1-hd-1106\n",
      "gpt-4o-2024-08-06\n",
      "gpt-4o-mini-2024-07-18\n",
      "gpt-4.1-mini\n",
      "gpt-4o-mini\n",
      "gpt-4o-mini-audio-preview-2024-12-17\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-4-turbo\n",
      "tts-1\n",
      "gpt-4-turbo-2024-04-09\n",
      "tts-1-1106\n",
      "gpt-4o-realtime-preview-2024-10-01\n",
      "gpt-4o-mini-transcribe\n",
      "gpt-4.1-mini-2025-04-14\n",
      "omni-moderation-2024-09-26\n",
      "o3-mini\n",
      "omni-moderation-latest\n",
      "gpt-4.1\n",
      "whisper-1\n",
      "gpt-4.1-2025-04-14\n",
      "o3\n",
      "o3-2025-04-16\n",
      "gpt-4o-audio-preview-2024-12-17\n",
      "o4-mini\n",
      "o4-mini-2025-04-16\n",
      "gpt-4o-realtime-preview-2024-12-17\n",
      "codex-mini-latest\n",
      "o1-preview-2024-09-12\n",
      "o1-preview\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "client = openai.OpenAI()\n",
    "models = client.models.list()\n",
    "\n",
    "for m in models.data:\n",
    "    print(m.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f32094d-23e4-4fc1-9656-678dc1fdfa11",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ed5285-2e43-4acf-bb91-23b3492eccbb",
   "metadata": {},
   "source": [
    "I hope you enjoyed this brief introduction to some of the capabilities of these AI Models and how they can be used for biomedical decision making. More information about advanced use case can be found in [OpenAI's documentation](https://platform.openai.com/docs/overview) or in the documentation website of your desired model. If you want to learn how these models work from an architecture perspective, [take a look at this tutorial](https://jalammar.github.io/illustrated-transformer/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2881c934-4f1b-4fb6-bf47-ba73613d63b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
